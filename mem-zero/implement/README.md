# Mem0 Memory Architecture with LangGraph Multi-Agent System

ÄÃ¢y lÃ  má»™t implementation demo cá»§a kiáº¿n trÃºc memory Mem0 Ä‘Æ°á»£c tÃ­ch há»£p vá»›i há»‡ thá»‘ng multi-agent sá»­ dá»¥ng LangGraph.

## ğŸ“‹ Má»¥c lá»¥c

1. [Tá»•ng quan](#tá»•ng-quan)
2. [Kiáº¿n trÃºc](#kiáº¿n-trÃºc)
3. [Pipeline Chi tiáº¿t](#pipeline-chi-tiáº¿t)
4. [CÃ i Ä‘áº·t](#cÃ i-Ä‘áº·t)
5. [Sá»­ dá»¥ng](#sá»­-dá»¥ng)
6. [Production Notes](#production-notes)
7. [Cáº¥u trÃºc dá»± Ã¡n](#cáº¥u-trÃºc-dá»±-Ã¡n)

---

## ğŸ¯ Tá»•ng quan

### Mem0 Memory Architecture

Mem0 lÃ  má»™t kiáº¿n trÃºc memory Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ:
- **NÃ©n há»™i thoáº¡i thÃ nh facts**: Chá»‰ lÆ°u nhá»¯ng sá»± tháº­t quan trá»ng, khÃ´ng lÆ°u toÃ n bá»™ há»™i thoáº¡i
- **Vector Search**: Sá»­ dá»¥ng vector database Ä‘á»ƒ tÃ¬m kiáº¿m memories liÃªn quan theo ngá»¯ nghÄ©a
- **Function Calling**: Sá»­ dá»¥ng LLM Ä‘á»ƒ quyáº¿t Ä‘á»‹nh ADD/UPDATE/DELETE/NOOP memories
- **Hiá»‡u quáº£ cao**: Target latency < 0.70s, tiáº¿t kiá»‡m ~90% chi phÃ­ so vá»›i full context RAG

### Multi-Agent System

Há»‡ thá»‘ng multi-agent bao gá»“m:
- **Supervisor Agent**: Route tasks Ä‘áº¿n cÃ¡c agent chuyÃªn biá»‡t
- **Sales Agent**: Xá»­ lÃ½ inquiries vá» sáº£n pháº©m
- **Support Agent**: Xá»­ lÃ½ technical support
- **General Agent**: Xá»­ lÃ½ cÃ¢u há»i chung

### Demo Features

- âœ… File-based vector store (mock cho demo)
- âœ… File-based conversation storage (mock cho demo)
- âœ… Mock embeddings (random vectors)
- âœ… LLM-based fact extraction
- âœ… LLM-based memory update decisions
- âœ… Multi-agent routing

---

## ğŸ—ï¸ Kiáº¿n trÃºc

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER INPUT                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SUPERVISOR AGENT (LangGraph)                    â”‚
â”‚              Routes to appropriate agent                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚               â”‚               â”‚
         â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SALES AGENT â”‚  â”‚SUPPORT AGENTâ”‚  â”‚GENERAL AGENTâ”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                â”‚                â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              MEM0 MEMORY MANAGER                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Stage 1: RETRIEVAL & GENERATION (Hot Path)          â”‚  â”‚
â”‚  â”‚  - Vector Search (Top-K memories)                    â”‚  â”‚
â”‚  â”‚  - Generate response with memories                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Stage 2: EXTRACTION & UPDATE (Cold Path)            â”‚  â”‚
â”‚  â”‚  - Extract facts from conversation                    â”‚  â”‚
â”‚  â”‚  - Decide operation (ADD/UPDATE/DELETE/NOOP)         â”‚  â”‚
â”‚  â”‚  - Update vector store                                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Stage 3: ASYNC SUMMARIZATION (Background)           â”‚  â”‚
â”‚  â”‚  - Update global summary periodically                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                      â”‚
               â–¼                      â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Vector Store    â”‚    â”‚  Storage         â”‚
    â”‚  (Memories)      â”‚    â”‚  (Context)       â”‚
    â”‚                  â”‚    â”‚                  â”‚
    â”‚  âš ï¸ Demo: File   â”‚    â”‚  âš ï¸ Demo: File   â”‚
    â”‚  Production:     â”‚    â”‚  Production:     â”‚
    â”‚  Qdrant/Pinecone â”‚    â”‚  Redis/Postgres  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

```
USER QUERY
    â”‚
    â”œâ”€â”€â–º Supervisor Node â”€â”€â–º Route to Agent
    â”‚                           â”‚
    â”‚                           â–¼
    â”‚                    Agent Node
    â”‚                           â”‚
    â”‚                           â”œâ”€â”€â–º Retrieve Memories (Vector Search)
    â”‚                           â”‚           â”‚
    â”‚                           â”‚           â–¼
    â”‚                           â”‚    Get Top-K Memories
    â”‚                           â”‚           â”‚
    â”‚                           â”‚           â–¼
    â”‚                           â”œâ”€â”€â–º Generate Response (with memories)
    â”‚                           â”‚           â”‚
    â”‚                           â”‚           â–¼
    â”‚                           â”‚    Return Response
    â”‚                           â”‚           â”‚
    â”‚                           â–¼           â”‚
    â”œâ”€â”€â–º Memory Update Node â—„â”€â”€â”˜           â”‚
    â”‚         â”‚                             â”‚
    â”‚         â”œâ”€â”€â–º Extract Facts            â”‚
    â”‚         â”‚         â”‚                   â”‚
    â”‚         â”‚         â–¼                   â”‚
    â”‚         â”‚    Get Facts List           â”‚
    â”‚         â”‚         â”‚                   â”‚
    â”‚         â”œâ”€â”€â–º For each fact:           â”‚
    â”‚         â”‚         â”‚                   â”‚
    â”‚         â”‚         â”œâ”€â”€â–º Search Similar Memories
    â”‚         â”‚         â”‚         â”‚
    â”‚         â”‚         â”‚         â–¼
    â”‚         â”‚         â”œâ”€â”€â–º Decide Operation (LLM)
    â”‚         â”‚         â”‚         â”‚
    â”‚         â”‚         â”‚         â–¼
    â”‚         â”‚         â””â”€â”€â–º Execute (ADD/UPDATE/DELETE/NOOP)
    â”‚         â”‚
    â”‚         â””â”€â”€â–º Update Conversation Context
    â”‚
    â–¼
RESPONSE TO USER
```

---

## ğŸ”„ Pipeline Chi tiáº¿t

### Stage 1: Retrieval & Generation (Hot Path)

**Má»¥c tiÃªu**: Tráº£ lá»i User nhanh nháº¥t cÃ³ thá»ƒ (Target: < 1.5s)

1. **Vector Search**:
   - Embed query text
   - Search vector DB vá»›i filter `user_id`
   - Láº¥y Top-K (k=10)

2. **Generation**:
   - ÄÆ°a memories vÃ o System Prompt
   - LLM generate response sá»­ dá»¥ng memories
   - Return response cho User

**Latency Target**: ~0.70s total

### Stage 2: Extraction & Update (Cold Path)

**Má»¥c tiÃªu**: Ghi nhá»› thÃ´ng tin má»›i, loáº¡i bá» tin cÅ©/sai

1. **Extraction (LLM Call 1)**:
   - TrÃ­ch xuáº¥t facts tá»« conversation
   - Input: (Q, A) + Global Summary + Recent Messages
   - Output: List of facts `Î© = [f1, f2, ...]`

2. **Update Loop** (cho má»—i fact):
   - **Step 3a**: Search tÆ°Æ¡ng Ä‘á»“ng trong Vector DB
   - **Step 3b**: Function Calling (LLM Call 2)
     - Quyáº¿t Ä‘á»‹nh: ADD / UPDATE / DELETE / NOOP
   - **Step 3c**: Execute operation

**Latency**: CÃ³ thá»ƒ cháº¡y async/background Ä‘á»ƒ khÃ´ng block response

### Stage 3: Async Summarization (Background)

**Trigger**: Cháº¡y sau má»—i N lÆ°á»£t há»™i thoáº¡i

**Action**: Cáº­p nháº­t Global Summary Ä‘á»ƒ phá»¥c vá»¥ cho Stage 2 láº§n sau

---

## ğŸ“¦ CÃ i Ä‘áº·t

### 1. Clone vÃ  cÃ i Ä‘áº·t dependencies

```bash
cd langgraph-memory/multi-agents-memory/mem-zero/implement

# Táº¡o virtual environment (khuyáº¿n nghá»‹)
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# hoáº·c
.venv\Scripts\activate  # Windows

# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt
```

### 2. Cáº¥u hÃ¬nh API Key

Táº¡o file `.env` trong thÆ° má»¥c `implement/`:

```env
# Chá»n provider: openai (default) hoáº·c ollama
LLM_PROVIDER=ollama

# Náº¿u dÃ¹ng Ollama (local)
# - Tool-calling model: functiongemma:270m
# - Normal model: hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF:latest
OLLAMA_MODEL=functiongemma:270m

# Náº¿u dÃ¹ng OpenAI
OPENAI_API_KEY=your_openai_api_key_here
```

Hoáº·c set environment variable:

```bash
export OPENAI_API_KEY=your_openai_api_key_here
```

### 3. Cháº¡y demo

```bash
python demo.py
```

**LÆ°u Ã½ vá»›i Ollama**
- CÃ i Ollama vÃ  pull model trÆ°á»›c:
  - `ollama pull functiongemma:270m`
  - `ollama pull hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF:latest`
- Äáº·t `LLM_PROVIDER=ollama` vÃ  chá»n `OLLAMA_MODEL` mong muá»‘n.

---

## ğŸš€ Sá»­ dá»¥ng

### Basic Usage

```python
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from src.memory.memory_manager import MemoryManager
from src.memory.vector_store import FileVectorStore
from src.memory.storage import FileStorage
from src.agents.graph import create_multi_agent_graph
import uuid

# Load environment
load_dotenv()

# Initialize components
vector_store = FileVectorStore(storage_path="./data/vector_store")
storage = FileStorage(storage_path="./data/storage")
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
memory_manager = MemoryManager(vector_store, storage, llm)

# Create graph
graph = create_multi_agent_graph(memory_manager, llm)

# Create initial state
user_id = "user_123"
session_id = f"session_{uuid.uuid4().hex[:8]}"

initial_state = {
    "messages": [HumanMessage(content="I need help with a product")],
    "next_agent": "general",
    "user_id": user_id,
    "session_id": session_id,
    "agent_id": "general",
    "memory_context": {}
}

# Run graph
result = graph.invoke(initial_state)

# Get response
response = result["messages"][-1].content
print(f"Response: {response}")
```

### Test Scenarios

Demo script (`demo.py`) test cÃ¡c scenarios:
1. Sales agent routing
2. Support agent routing
3. General agent routing
4. Memory storage (user preferences)
5. Memory retrieval
6. Memory update (contradictions)

### Interactive Testing (Turn 1..N)

Báº¡n cÃ³ thá»ƒ test memory liÃªn tá»¥c theo turn (vd 1..10) báº±ng cháº¿ Ä‘á»™ interactive:

```bash
python demo.py
```

- GÃµ message vÃ  nháº¥n Enter Ä‘á»ƒ cháº¡y 1 turn
- GÃµ `q` hoáº·c `quit` Ä‘á»ƒ thoÃ¡t
- Log sáº½ hiá»ƒn thá»‹:
  - **[TIME]** cho tá»«ng bÆ°á»›c (search/generate/extract/updateâ€¦)
  - **[ROUTE]** supervisor route sang agent nÃ o
  - **[MEMORY_RETRIEVED]** sá»‘ lÆ°á»£ng memory id Ä‘Æ°á»£c retrieve
  - **[CONTEXT]** sá»‘ lÆ°á»£ng recent_messages (rolling window tá»‘i Ä‘a 10)

---

## âš ï¸ Production Notes

### Components cáº§n thay tháº¿ cho Production

#### 1. Vector Store

**Demo**: File-based mock vá»›i random embeddings

**Production**: 
- Qdrant (recommended)
- Pinecone (cloud-based)
- ChromaDB (open-source)
- Weaviate (self-hosted)
- pgvector (PostgreSQL extension)

**Code location**: `src/memory/vector_store.py`

#### 2. Embedding Model

**Demo**: Random vectors (mock)

**Production**:
- OpenAI: `text-embedding-3-small` (1536 dim) hoáº·c `text-embedding-3-large` (3072 dim)
- Sentence Transformers: `sentence-transformers/all-MiniLM-L6-v2` (384 dim)
- Google: `textembedding-gecko@003`

**Code location**: `src/memory/memory_manager.py::_generate_embedding()`

#### 3. Conversation Storage

**Demo**: File-based JSON storage

**Production**:
- Redis (cho session-level data vá»›i TTL)
- PostgreSQL (cho persistent conversation data)
- MongoDB (cho flexible schema)

**Code location**: `src/memory/storage.py`

#### 4. Async Processing

**Demo**: Synchronous execution (memory update blocks response)

**Production**:
- Run memory update in background (Celery, RQ, Background Tasks)
- Use queue (Redis Queue) Ä‘á»ƒ serialize updates per user_id
- Hot Path (response) vÃ  Cold Path (update) nÃªn cháº¡y song song

**Code location**: `src/agents/graph.py::memory_update_node()`

#### 5. Summarization

**Demo**: Not implemented (placeholder)

**Production**:
- Background job (Celery, Cron, etc.)
- Run sau má»—i N turns (e.g., 5-10 turns)
- Update global summary Ä‘á»ƒ tá»‘i Æ°u extraction

**Code location**: `src/memory/memory_manager.py::summarize_conversation()`

### Production Checklist

- [ ] Replace file-based vector store vá»›i Qdrant/Pinecone
- [ ] Replace mock embeddings vá»›i OpenAI/Sentence Transformers
- [ ] Replace file storage vá»›i Redis/PostgreSQL
- [ ] Implement async memory update (background tasks)
- [ ] Implement async summarization (background jobs)
- [ ] Add error handling vÃ  retry logic
- [ ] Add logging vÃ  monitoring
- [ ] Add rate limiting
- [ ] Add authentication/authorization
- [ ] Add metrics vÃ  observability
- [ ] Add tests (unit, integration, e2e)
- [ ] Add deployment configs (Docker, Kubernetes, etc.)

---

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
implement/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ memory/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models.py              # Data models (MemoryItem, ConversationContext, MemoryOperation)
â”‚   â”‚   â”œâ”€â”€ vector_store.py        # File-based vector store (âš ï¸ Demo)
â”‚   â”‚   â”œâ”€â”€ storage.py             # File-based storage (âš ï¸ Demo)
â”‚   â”‚   â””â”€â”€ memory_manager.py      # Core mem0 pipeline implementation
â”‚   â””â”€â”€ agents/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ state.py               # LangGraph state schema
â”‚       â””â”€â”€ graph.py               # Multi-agent graph definition
â”œâ”€â”€ demo.py                        # Demo/test script
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ pyproject.toml                 # Project metadata
â””â”€â”€ README.md                      # This file
```

---

## ğŸ“š TÃ i liá»‡u tham kháº£o

- [Mem0 Architecture Note](./architecture_note.md)
- [LangGraph Multi-Agent Documentation](https://langchain-ai.github.io/langgraph/how-tos/multi_agent/)
- [LangGraph Memory Documentation](https://langchain-ai.github.io/langgraph/how-tos/memory/)

---

## ğŸ”§ Troubleshooting

### Issue: OPENAI_API_KEY not found

**Solution**: Set `OPENAI_API_KEY` in `.env` file or environment variable

### Issue: Import errors

**Solution**: Make sure you've installed all dependencies:
```bash
pip install -r requirements.txt
```

### Issue: Data not persisting

**Solution**: Check that `./data/` directory is writable. Data is stored in:
- `./data/vector_store/` - Vector database files
- `./data/storage/` - Conversation context files

---

## ğŸ“ Notes

- ÄÃ¢y lÃ  má»™t **demo implementation** Ä‘á»ƒ test feasibility
- Má»™t sá»‘ components lÃ  **mock** (file-based storage, random embeddings)
- Cho production, cáº§n thay tháº¿ vá»›i real implementations (see Production Notes)
- Code cÃ³ **comments chi tiáº¿t** Ä‘á»ƒ chá»‰ rÃµ production requirements

---

## ğŸ¯ Next Steps

1. Test vá»›i real embeddings (OpenAI, Sentence Transformers)
2. Test vá»›i real vector DB (Qdrant, Pinecone)
3. Implement async memory update
4. Implement async summarization
5. Add comprehensive tests
6. Deploy to production environment

---

**Version**: 0.1.0  
**Last Updated**: 2025-01-30
